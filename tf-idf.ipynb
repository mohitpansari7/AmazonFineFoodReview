{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing tf-idf in Amazon Fine Food Review Database from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('./database.sqlite')\n",
    "rawData = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3 LIMIT 5000\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2715.98100</td>\n",
       "      <td>1.573800</td>\n",
       "      <td>2.017800</td>\n",
       "      <td>4.258000</td>\n",
       "      <td>1.294917e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1567.91492</td>\n",
       "      <td>5.051184</td>\n",
       "      <td>5.616956</td>\n",
       "      <td>1.331236</td>\n",
       "      <td>4.783329e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.617184e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1350.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.270685e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2720.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.309306e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4069.25000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.330387e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5427.00000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  HelpfulnessNumerator  HelpfulnessDenominator        Score  \\\n",
       "count  5000.00000           5000.000000             5000.000000  5000.000000   \n",
       "mean   2715.98100              1.573800                2.017800     4.258000   \n",
       "std    1567.91492              5.051184                5.616956     1.331236   \n",
       "min       1.00000              0.000000                0.000000     1.000000   \n",
       "25%    1350.75000              0.000000                0.000000     4.000000   \n",
       "50%    2720.50000              0.000000                1.000000     5.000000   \n",
       "75%    4069.25000              2.000000                2.000000     5.000000   \n",
       "max    5427.00000            165.000000              168.000000     5.000000   \n",
       "\n",
       "               Time  \n",
       "count  5.000000e+03  \n",
       "mean   1.294917e+09  \n",
       "std    4.783329e+07  \n",
       "min    9.617184e+08  \n",
       "25%    1.270685e+09  \n",
       "50%    1.309306e+09  \n",
       "75%    1.330387e+09  \n",
       "max    1.351210e+09  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      5000 non-null   int64 \n",
      " 1   ProductId               5000 non-null   object\n",
      " 2   UserId                  5000 non-null   object\n",
      " 3   ProfileName             5000 non-null   object\n",
      " 4   HelpfulnessNumerator    5000 non-null   int64 \n",
      " 5   HelpfulnessDenominator  5000 non-null   int64 \n",
      " 6   Score                   5000 non-null   int64 \n",
      " 7   Time                    5000 non-null   int64 \n",
      " 8   Summary                 5000 non-null   object\n",
      " 9   Text                    5000 non-null   object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "rawData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Distinguishing Score Column as Positive and Negative based on Score and separating it from training dataFrame\n",
    "Modified Score column would be used to match our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(score):\n",
    "    if score > 3:\n",
    "        return 'Positive'\n",
    "    return 'Negative'\n",
    "\n",
    "actualScore = rawData['Score']\n",
    "rawData['Score'] = actualScore.map(partition)\n",
    "modifiedData = rawData.drop('Score', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the required data with us in-place,\n",
    "Lets figure out how to clean the data of text and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regular expression changing text of negative and other words to their original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracting(str):\n",
    "    str = re.sub(r\"wont't\", 'will not', str)\n",
    "    str = re.sub(r\"can\\'t\", 'cannot', str)\n",
    "\n",
    "    str = re.sub(r\"n\\'t\", \" not\", str)\n",
    "    str = re.sub(r\"\\'re\", \" are\", str)\n",
    "    str = re.sub(r\"\\'s\", \" is\", str)\n",
    "    str = re.sub(r\"\\'d\", \" would\", str)\n",
    "    str = re.sub(r\"\\'ll\", \" will\", str)\n",
    "    str = re.sub(r\"\\'t\", \" not\", str)\n",
    "    str = re.sub(r\"\\'ve\", \" have\", str)\n",
    "    str = re.sub(r\"\\'m\", \" am\", str)\n",
    "    return str    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring our own stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1144.58it/s]\n"
     ]
    }
   ],
   "source": [
    "processedText = []\n",
    "\n",
    "for sentence in tqdm(modifiedData['Text'].values):\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
    "    sentence = decontracting(sentence)\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
    "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
    "    processedText.append(sentence.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now processing same rules of Summary as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1727.67it/s]\n"
     ]
    }
   ],
   "source": [
    "processedSummary = []\n",
    "\n",
    "for sentence in tqdm(modifiedData['Summary'].values):\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
    "    sentence = decontracting(sentence)\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
    "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
    "    processedSummary.append(sentence.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets begin with for what we are here - featurization of tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDistinctWords = []\n",
    "\n",
    "for sent in processedText:\n",
    "    for eachWord in sent.split(' '):\n",
    "        listOfDistinctWords.append(eachWord)\n",
    "\n",
    "listOfDistinctWords = set(listOfDistinctWords)\n",
    "listOfDistinctWords = list(listOfDistinctWords)\n",
    "listOfDistinctWords.sort()\n",
    "#listOfDistinctWords = listOfDistinctWords[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "1249\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tfIdfVect = []\n",
    "\n",
    "print(processedText[0])\n",
    "print(listOfDistinctWords.index('bought'))\n",
    "\n",
    "tfDict = np.zeros((len(processedText), len(listOfDistinctWords)))\n",
    "\n",
    "for i in range(0, len(processedText)):\n",
    "    tempArr = processedText[i].split(' ')\n",
    "\n",
    "    for j in range(0, len(tempArr)):\n",
    "        tfDict[i][listOfDistinctWords.index(tempArr[j])] += 1\n",
    "    \n",
    "    for j in range(0, len(listOfDistinctWords)):\n",
    "        tfDict[i][j] = tfDict[i][j]/len(tempArr)\n",
    "\n",
    "print(tfDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13016)\n"
     ]
    }
   ],
   "source": [
    "print(tfDict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfOfEachWord = {}\n",
    "\n",
    "wordFreqInDc = {}\n",
    "\n",
    "for eachWord in listOfDistinctWords:\n",
    "    wordFreqInDc[eachWord] = 0\n",
    "\n",
    "for eachSent in processedText:\n",
    "    tempSent = eachSent.split(' ')\n",
    "    tempSent = set(tempSent)\n",
    "    tempSent = list(tempSent)\n",
    "    for eachWord in tempSent:\n",
    "        wordFreqInDc[eachWord] += 1\n",
    "\n",
    "numberOfReviews = len(processedText)\n",
    "\n",
    "for eachWord in wordFreqInDc:\n",
    "    idfOfEachWord[eachWord] = math.log(numberOfReviews/(wordFreqInDc[eachWord] + 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 13016\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "finalTfIdf = np.zeros((len(tfDict), len(tfDict[0])))\n",
    "\n",
    "print(len(tfDict), len(tfDict[0]))\n",
    "\n",
    "for i in range(0, len(tfDict)):\n",
    "    for j in range(0, len(tfDict[0])):\n",
    "        finalTfIdf[i][j] = tfDict[i][j] * idfOfEachWord[listOfDistinctWords[j]]\n",
    "\n",
    "print(finalTfIdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7679c2132d3f6ce38c9df14d554b39c06862b36a4e6689c81f9ae15bd0911d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
